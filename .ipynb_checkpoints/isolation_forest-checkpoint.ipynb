{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502b9bd3-6918-47d8-961e-1d6d7db163bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import gzip\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy \n",
    "from scipy import signal\n",
    "\n",
    "# graph\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# signal prepocessing\n",
    "import biosppy\n",
    "from biosppy.signals import ecg\n",
    "\n",
    "import pyhrv\n",
    "import pyhrv.tools as tools\n",
    "import pyhrv.time_domain as td\n",
    "\n",
    "# sklean\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "#pyod isolation forest\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c22236-72de-4071-a324-2e320fd2ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_isft = IsolationForest(max_samples=100, random_state=0)\n",
    "sk_isft.fit(X_train)\n",
    "'''\n",
    "    X{array-like, sparse matrix} of shape (n_samples, n_features)\n",
    "\n",
    "        The input samples. Use dtype=np.float32 for maximum efficiency. Sparse matrices are also supported, use sparse csc_matrix for maximum efficiency.\n",
    "    yIgnored\n",
    "\n",
    "        Not used, present for API consistency by convention.\n",
    "    sample_weightarray-like of shape (n_samples,), default=None\n",
    "\n",
    "        Sample weights. If None, then samples are equally weighted.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ced7aa-4bb5-43ae-9d36-f9f8ac05f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    sk_isft,\n",
    "    X,\n",
    "    response_method=\"decision_function\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "disp.ax_.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor=\"k\")\n",
    "disp.ax_.set_title(\"Path length decision boundary \\nof IsolationForest\")\n",
    "plt.axis(\"square\")\n",
    "plt.legend(handles=handles, labels=[\"outliers\", \"inliers\"], title=\"true class\")\n",
    "plt.colorbar(disp.ax_.collections[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e890f8c-8157-4220-95d5-ff1205ce41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination = 0.05 # percentage of outliers\n",
    "n_train =        # number of training points\n",
    "n_test =         # number of testing points\n",
    "n_features =       # number of features\n",
    "X_train, X_test, y_train, y_test = generate_data(\n",
    "    n_train = n_train, \n",
    "    n_test = n_test, \n",
    "    n_features = n_features, \n",
    "    contamination = contamination, \n",
    "    random_state = 42)\n",
    "\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "X_train_pd.head()\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X_train_pd[0], X_train_pd[1], c=y_train, alpha=0.8)\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel('x0')\n",
    "plt.ylabel('x1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131037a-d055-43e9-8701-3b8fc19e435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "po_isft = IForest(contamination=0.05, max_samples=40, behaviour='new') \n",
    "po_isft.fit(X_train)\n",
    "\n",
    "# Training data\n",
    "y_train_scores = isft.decision_function(X_train)\n",
    "y_train_pred = isft.predict(X_train)\n",
    "\n",
    "# Test data\n",
    "y_test_scores = isft.decision_function(X_test)\n",
    "y_test_pred = isft.predict(X_test) # outlier labels (0 or 1)\n",
    "\n",
    "# Threshold for the defined comtanimation rate\n",
    "print(\"The threshold for the defined contamination rate:\" , isft.threshold_)\n",
    "\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "print(\"The training data:\", count_stat(y_train_pred))\n",
    "print(\"The training data:\", count_stat(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c40c87-922a-428f-9ad6-f50c8996561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(po_isft.get_params())\n",
    "po_isft_vi = isft.feature_importances_\n",
    "print(po_isft_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bcab6-9f76-4160-bedf-d995a8dbc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_plot = pd.DataFrame({'x_axis':X_train_pd.columns,\n",
    "              'y_axis':isft_vi}).sort_values(by='y_axis',ascending=True)\n",
    "for_plot['y_axis'].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbeda5e-c4dc-4b89-94d3-5eeed9e4bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train_scores, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Outlier score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bf2dd-3c9c-4ced-b538-12eafc5ba37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = po_isft.threshold_ # Or other value from the above histogram\n",
    "\n",
    "def descriptive_stat_threshold(df,pred_score, threshold):\n",
    "    # Let's see how many '0's and '1's.\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
    "\n",
    "    # Now let's show the summary statistics:\n",
    "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
    "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
    "    return (stat)\n",
    "\n",
    "descriptive_stat_threshold(X_train,y_train_scores, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
